<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Agent</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
</head>
<body>
    <div class="main-container">
        <div class="sidebar">
            <button id="startButton" class="mic-button">Start Voice Agent</button>
            <div id="status" class="status">Status: Inactive</div>
            <div class="audio-controls">
                <div class="device-select">
                    <label for="voiceModel">Voice Model:</label>
                    <select id="voiceModel"></select>
                </div>
            </div>
            <div class="controls">
                <label class="toggle">
                    <input type="checkbox" id="holdToTalk">
                    <span class="slider"></span>
                </label>
                <label for="holdToTalk" class="toggle-label">Hold-to-Talk</label>
            </div>
            <div class="controls">
                <label class="toggle">
                    <input type="checkbox" id="showLogs">
                    <span class="slider"></span>
                </label>
                <label for="showLogs" class="toggle-label">Show Debug Logs</label>
            </div>
            <hr>
            <div class="logs-container syncscroll" name="log-container" id="logsContainer" style="display: none;">
                <div id="logs" class="logs"></div>
            </div>
        </div>
        <div class="content-container syncscroll" name="log-container">
            <div id="conversation" class="conversation-panel"></div>
        </div>
    </div>

    <script>
        document.addEventListener("DOMContentLoaded", () => {
            const startButton = document.getElementById('startButton');
            const statusDiv = document.getElementById('status');
            const logsDiv = document.getElementById('logs');
            const conversationDiv = document.getElementById('conversation');
            const voiceModelSelect = document.getElementById('voiceModel');
            const holdToTalkCheckbox = document.getElementById('holdToTalk');
            const showLogsCheckbox = document.getElementById('showLogs');
            const logsContainer = document.getElementById('logsContainer');
            const syncScrollContainers = document.querySelectorAll('.syncscroll');

            let socket;
            let audioContext;
            let audioWorkletNode;
            let microphoneStream;
            let audioQueue = [];
            let isPlaying = false;
            let isActive = false;
            let isMuted = false;
            let holdToTalkActive = false;
            let nextPlayTime = 0; // For continuous audio scheduling
            let lastAudioSendTime = 0;
            const AUDIO_SEND_INTERVAL = 20; // Send audio every 20ms (was 100ms - too aggressive)

            // --- UI and Logging ---

            function logMessage(message, type = 'info') {
                const logEntry = document.createElement('div');
                logEntry.className = `log-entry log-${type}`;
                logEntry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
                logsDiv.appendChild(logEntry);
                logsDiv.scrollTop = logsDiv.scrollHeight;
            }

            function addConversationMessage(role, text) {
                const messageBubble = document.createElement('div');
                messageBubble.className = `message-bubble ${role}`;
                messageBubble.textContent = text;
                conversationDiv.appendChild(messageBubble);
                conversationDiv.scrollTop = conversationDiv.scrollHeight;
            }

            function setStatus(text) {
                statusDiv.textContent = `Status: ${text}`;
            }

            // --- Scroll Syncing ---
            syncScrollContainers.forEach(el => {
                el.addEventListener('scroll', () => {
                    const scrollY = el.scrollTop;
                    syncScrollContainers.forEach(otherEl => {
                        if (otherEl !== el) {
                            otherEl.scrollTop = scrollY;
                        }
                    });
                });
            });

            // --- API Calls ---

            async function fetchVoiceModels() {
                try {
                    const response = await fetch('/tts-models');
                    const data = await response.json();
                    if (data.models) {
                        voiceModelSelect.innerHTML = '';
                        data.models.forEach(model => {
                            const option = document.createElement('option');
                            option.value = model.name;
                            option.textContent = model.display_name;
                            voiceModelSelect.appendChild(option);
                        });
                        voiceModelSelect.value = 'aura-2-thalia-en'; // Default
                    } else {
                        logMessage('Failed to load voice models.', 'error');
                    }
                } catch (error) {
                    logMessage(`Error fetching voice models: ${error}`, 'error');
                }
            }
            
            // --- Core Audio Logic ---

            async function startAudio() {
                if (isActive) return;
                isActive = true;
                setStatus('Initializing...');
                logMessage('Starting audio pipeline...');

                try {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                    if (audioContext.state === 'suspended') await audioContext.resume();

                    await audioContext.audioWorklet.addModule('/audio-processor.js');
                    audioWorkletNode = new AudioWorkletNode(audioContext, 'audio-processor');

                    microphoneStream = await navigator.mediaDevices.getUserMedia({ audio: { sampleRate: 16000, channelCount: 1 }});
                    const microphone = audioContext.createMediaStreamSource(microphoneStream);
                    microphone.connect(audioWorkletNode);

                    audioWorkletNode.port.onmessage = (event) => {
                        if (socket && socket.connected && !isMuted) {
                            // Very light throttling to prevent SocketIO overload while maintaining speech quality
                            if (Math.random() < 0.85) { // Send 85% of audio chunks
                                socket.emit('user_audio', event.data);
                                
                                // Log audio data being sent (occasionally)
                                if (Math.random() < 0.01) { // 1% of chunks
                                    logMessage(`Sending user audio: ${event.data.byteLength} bytes`);
                                }
                            }
                        } else if (isMuted) {
                            // Log when audio is muted (less frequently)
                            if (Math.random() < 0.005) { // 0.5% of chunks
                                logMessage(`Audio muted - Hold-to-Talk: ${holdToTalkActive ? 'ON' : 'OFF'}`);
                            }
                        } else if (!socket || !socket.connected) {
                            // Log connection issues
                            if (Math.random() < 0.005) {
                                logMessage(`Audio not sent - Socket connected: ${socket?.connected || false}`);
                            }
                        }
                    };
                    
                    logMessage('Audio pipeline ready.');
                    logMessage(`Microphone connected - Sample rate: ${audioContext.sampleRate}Hz`);
                    logMessage(`Audio mode: ${holdToTalkActive ? 'Hold-to-talk (Press Space)' : 'Continuous listening'}`);
                    connectSocket();

                } catch (error) {
                    logMessage(`Failed to start audio: ${error}`, 'error');
                    if (error.name === 'NotAllowedError') {
                        logMessage('Microphone permission denied. Please allow microphone access and try again.', 'error');
                    } else if (error.name === 'NotFoundError') {
                        logMessage('No microphone found. Please connect a microphone and try again.', 'error');
                    }
                    setStatus('Error');
                    isActive = false;
                }
            }

            function stopAudio() {
                if (!isActive) return;
                isActive = false;
                logMessage('Stopping audio pipeline...');
                if (socket) {
                    socket.emit('stop_voice_agent');
                    socket.disconnect();
                }
                if (microphoneStream) {
                    microphoneStream.getTracks().forEach(track => track.stop());
                }
                if (audioContext && audioContext.state !== 'closed') {
                    audioContext.close();
                }
                audioQueue = [];
                isPlaying = false;
                setStatus('Inactive');
                startButton.textContent = 'Start Voice Agent';
            }

            function playNextAudioChunk() {
                if (audioQueue.length === 0 || !audioContext) return;

                const audioData = audioQueue.shift();
                
                if (audioContext.state === 'suspended') {
                    audioContext.resume().then(() => {
                        playRawPCM(audioData);
                    });
                } else {
                    playRawPCM(audioData);
                }
            }

            function playRawPCM(audioData) {
                try {
                    // Convert Uint8Array to Int16Array (16-bit PCM)
                    const numSamples = audioData.length / 2;
                    const pcmData = new Int16Array(audioData.buffer, audioData.byteOffset, numSamples);
                    
                    // Create AudioBuffer
                    const audioBuffer = audioContext.createBuffer(1, numSamples, 24000);
                    const channelData = audioBuffer.getChannelData(0);
                    
                    // Convert Int16 to Float32 and fill the buffer
                    for (let i = 0; i < numSamples; i++) {
                        const sample = pcmData[i];
                        channelData[i] = sample / 32768.0;
                    }
                    
                    // Schedule the buffer for continuous playback
                    const source = audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioContext.destination);
                    
                    // Calculate when to start this chunk for smooth playback
                    const currentTime = audioContext.currentTime;
                    if (nextPlayTime <= currentTime) {
                        nextPlayTime = currentTime + 0.01; // Small buffer to avoid glitches
                    }
                    
                    source.start(nextPlayTime);
                    nextPlayTime += audioBuffer.duration; // Schedule next chunk right after this one
                    
                    // Log less frequently
                    if (Math.random() < 0.05) { // 5% of chunks (was 10%)
                        logMessage(`Playing audio chunk: ${numSamples} samples, scheduled at ${nextPlayTime.toFixed(3)}s`);
                    }
                    
                } catch (error) {
                    logMessage(`Error playing raw PCM: ${error}`, 'error');
                    console.error('Raw PCM playback error:', error);
                }
            }

            // --- WebSocket Logic ---

            function connectSocket() {
                if (socket && socket.connected) return;

                socket = io();

                socket.on('connect', () => {
                    logMessage('Socket connected successfully.');
                    setStatus('Connected, starting agent...');
                    const sessionConfig = {
                        voiceModel: voiceModelSelect.value,
                    };
                    socket.emit('start_voice_agent', sessionConfig);
                });

                socket.on('disconnect', () => {
                    logMessage('Socket disconnected.', 'warn');
                    stopAudio(); // Full cleanup on disconnect
                });

                socket.on('agent_response', (data) => {
                    logMessage(`Agent Response: ${JSON.stringify(data)}`);
                    switch (data.type) {
                        case 'Welcome':
                            setStatus('Agent Ready');
                            // Show current audio mode status
                            if (holdToTalkActive) {
                                logMessage('Hold-to-talk mode - Press and hold Space to speak');
                                setStatus('Agent Ready - Press Space to talk');
                            } else {
                                logMessage('Continuous listening mode - Speak anytime');
                                setStatus('Agent Ready - Listening...');
                            }
                            break;
                        case 'ConversationText':
                            addConversationMessage('assistant', data.content);
                            break;
                        case 'Error':
                            logMessage(`Agent Error: ${data.description}`, 'error');
                            setStatus('Error');
                            break;
                    }
                });

                socket.on('agent_audio', (chunk) => {
                    audioQueue.push(new Uint8Array(chunk));
                    playNextAudioChunk();
                });
            }

            // --- Event Listeners ---

            startButton.addEventListener('click', () => {
                if (isActive) {
                    stopAudio();
                } else {
                    startAudio();
                    startButton.textContent = 'Stop Voice Agent';
                }
            });

            holdToTalkCheckbox.addEventListener('change', (e) => {
                holdToTalkActive = e.target.checked;
                logMessage(`Hold-to-Talk ${holdToTalkActive ? 'activated' : 'deactivated'}.`);
                if (!holdToTalkActive) {
                    isMuted = false; // Unmute if mode is turned off
                    setStatus('Agent Ready - Continuous listening');
                    logMessage('Continuous audio mode enabled');
                } else {
                    isMuted = true; // Mute by default in hold-to-talk mode
                    setStatus('Agent Ready - Press Space to talk');
                    logMessage('Hold-to-talk mode enabled - Press and hold Space to speak');
                }
            });

            showLogsCheckbox.addEventListener('change', (e) => {
                if (e.target.checked) {
                    logsContainer.style.display = 'block';
                    logMessage('Debug logs are now visible');
                } else {
                    logsContainer.style.display = 'none';
                }
            });

            document.body.addEventListener('keydown', (e) => {
                if (e.code === 'Space' && holdToTalkActive && isMuted) {
                    e.preventDefault();
                    isMuted = false;
                    logMessage('Speaking...', 'user');
                    setStatus('Listening...');
                }
            });

            document.body.addEventListener('keyup', (e) => {
                if (e.code === 'Space' && holdToTalkActive && !isMuted) {
                    e.preventDefault();
                    isMuted = true;
                    logMessage('Stopped speaking.');
                     setStatus('Agent Ready');
                }
            });

            fetchVoiceModels();
        });
    </script>
</body>
</html>