<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Agent</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
</head>
<body>
    <div class="main-container">
        <div class="sidebar">
            <button id="startButton" class="mic-button">Start Voice Agent</button>
            <div id="status" class="status">Status: Inactive</div>
            <div class="audio-controls">
                <div class="device-select">
                    <label for="voiceModel">Voice Model:</label>
                    <select id="voiceModel"></select>
                </div>
            </div>
            <div class="controls">
                <label class="toggle">
                    <input type="checkbox" id="holdToTalk">
                    <span class="slider"></span>
                </label>
                <label for="holdToTalk" class="toggle-label">Hold-to-Talk</label>
            </div>
            <hr>
            <div class="logs-container syncscroll" name="log-container">
                <div id="logs" class="logs"></div>
            </div>
        </div>
        <div class="content-container syncscroll" name="log-container">
            <div id="conversation" class="conversation-panel"></div>
        </div>
    </div>

    <script>
        document.addEventListener("DOMContentLoaded", () => {
            const startButton = document.getElementById('startButton');
            const statusDiv = document.getElementById('status');
            const logsDiv = document.getElementById('logs');
            const conversationDiv = document.getElementById('conversation');
            const voiceModelSelect = document.getElementById('voiceModel');
            const holdToTalkCheckbox = document.getElementById('holdToTalk');
            const syncScrollContainers = document.querySelectorAll('.syncscroll');

            let socket;
            let audioContext;
            let audioWorkletNode;
            let microphoneStream;
            let audioQueue = [];
            let isPlaying = false;
            let isActive = false;
            let isMuted = false;
            let holdToTalkActive = false;

            // --- UI and Logging ---

            function logMessage(message, type = 'info') {
                const logEntry = document.createElement('div');
                logEntry.className = `log-entry log-${type}`;
                logEntry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
                logsDiv.appendChild(logEntry);
                logsDiv.scrollTop = logsDiv.scrollHeight;
            }

            function addConversationMessage(role, text) {
                const messageBubble = document.createElement('div');
                messageBubble.className = `message-bubble ${role}`;
                messageBubble.textContent = text;
                conversationDiv.appendChild(messageBubble);
                conversationDiv.scrollTop = conversationDiv.scrollHeight;
            }

            function setStatus(text) {
                statusDiv.textContent = `Status: ${text}`;
            }

            // --- Scroll Syncing ---
            syncScrollContainers.forEach(el => {
                el.addEventListener('scroll', () => {
                    const scrollY = el.scrollTop;
                    syncScrollContainers.forEach(otherEl => {
                        if (otherEl !== el) {
                            otherEl.scrollTop = scrollY;
                        }
                    });
                });
            });

            // --- API Calls ---

            async function fetchVoiceModels() {
                try {
                    const response = await fetch('/tts-models');
                    const data = await response.json();
                    if (data.models) {
                        voiceModelSelect.innerHTML = '';
                        data.models.forEach(model => {
                            const option = document.createElement('option');
                            option.value = model.name;
                            option.textContent = model.display_name;
                            voiceModelSelect.appendChild(option);
                        });
                        voiceModelSelect.value = 'aura-2-thalia-en'; // Default
                    } else {
                        logMessage('Failed to load voice models.', 'error');
                    }
                } catch (error) {
                    logMessage(`Error fetching voice models: ${error}`, 'error');
                }
            }
            
            // --- Core Audio Logic ---

            async function startAudio() {
                if (isActive) return;
                isActive = true;
                setStatus('Initializing...');
                logMessage('Starting audio pipeline...');

                try {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                    if (audioContext.state === 'suspended') await audioContext.resume();

                    await audioContext.audioWorklet.addModule('/audio-processor.js');
                    audioWorkletNode = new AudioWorkletNode(audioContext, 'audio-processor');

                    microphoneStream = await navigator.mediaDevices.getUserMedia({ audio: { sampleRate: 16000, channelCount: 1 }});
                    const microphone = audioContext.createMediaStreamSource(microphoneStream);
                    microphone.connect(audioWorkletNode);

                    audioWorkletNode.port.onmessage = (event) => {
                        if (socket && socket.connected && !isMuted) {
                            socket.emit('user_audio', event.data);
                        }
                    };
                    
                    logMessage('Audio pipeline ready.');
                    connectSocket();

                } catch (error) {
                    logMessage(`Failed to start audio: ${error}`, 'error');
                    setStatus('Error');
                    isActive = false;
                }
            }

            function stopAudio() {
                if (!isActive) return;
                isActive = false;
                logMessage('Stopping audio pipeline...');
                if (socket) {
                    socket.emit('stop_voice_agent');
                    socket.disconnect();
                }
                if (microphoneStream) {
                    microphoneStream.getTracks().forEach(track => track.stop());
                }
                if (audioContext && audioContext.state !== 'closed') {
                    audioContext.close();
                }
                audioQueue = [];
                isPlaying = false;
                setStatus('Inactive');
                startButton.textContent = 'Start Voice Agent';
            }

            function playNextAudioChunk() {
                if (isPlaying || audioQueue.length === 0) return;
                isPlaying = true;

                const audioData = audioQueue.shift();
                audioContext.decodeAudioData(audioData.buffer, (buffer) => {
                    const source = audioContext.createBufferSource();
                    source.buffer = buffer;
                    source.connect(audioContext.destination);
                    source.start(0);
                    source.onended = () => {
                        isPlaying = false;
                        playNextAudioChunk(); // Play next in queue
                    };
                }, (error) => {
                    logMessage(`Error decoding audio: ${error}`, 'error');
                    isPlaying = false;
                    playNextAudioChunk();
                });
            }

            // --- WebSocket Logic ---

            function connectSocket() {
                if (socket && socket.connected) return;

                socket = io();

                socket.on('connect', () => {
                    logMessage('Socket connected successfully.');
                    setStatus('Connected, starting agent...');
                    const sessionConfig = {
                        voiceModel: voiceModelSelect.value,
                    };
                    socket.emit('start_voice_agent', sessionConfig);
                });

                socket.on('disconnect', () => {
                    logMessage('Socket disconnected.', 'warn');
                    stopAudio(); // Full cleanup on disconnect
                });

                socket.on('agent_response', (data) => {
                    logMessage(`Agent Response: ${JSON.stringify(data)}`);
                    switch (data.type) {
                        case 'Welcome':
                            setStatus('Agent Ready');
                            break;
                        case 'ConversationText':
                            addConversationMessage('assistant', data.content);
                            break;
                        case 'Error':
                            logMessage(`Agent Error: ${data.description}`, 'error');
                            setStatus('Error');
                            break;
                    }
                });

                socket.on('agent_audio', (chunk) => {
                    audioQueue.push(new Uint8Array(chunk));
                    playNextAudioChunk();
                });
            }

            // --- Event Listeners ---

            startButton.addEventListener('click', () => {
                if (isActive) {
                    stopAudio();
                } else {
                    startAudio();
                    startButton.textContent = 'Stop Voice Agent';
                }
            });

            holdToTalkCheckbox.addEventListener('change', (e) => {
                holdToTalkActive = e.target.checked;
                logMessage(`Hold-to-Talk ${holdToTalkActive ? 'activated' : 'deactivated'}.`);
                if (!holdToTalkActive) {
                    isMuted = false; // Unmute if mode is turned off
                } else {
                    isMuted = true; // Mute by default in hold-to-talk mode
                }
            });

            document.body.addEventListener('keydown', (e) => {
                if (e.code === 'Space' && holdToTalkActive && isMuted) {
                    e.preventDefault();
                    isMuted = false;
                    logMessage('Speaking...', 'user');
                    setStatus('Listening...');
                }
            });

            document.body.addEventListener('keyup', (e) => {
                if (e.code === 'Space' && holdToTalkActive && !isMuted) {
                    e.preventDefault();
                    isMuted = true;
                    logMessage('Stopped speaking.');
                     setStatus('Agent Ready');
                }
            });

            fetchVoiceModels();
        });
    </script>
</body>
</html>