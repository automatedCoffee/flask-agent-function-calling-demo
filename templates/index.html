<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Agent</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
</head>
<body>
    <div class="main-container">
        <div class="sidebar">
            <button id="startButton" class="mic-button">Start Voice Agent</button>
            <div id="status" class="status">Status: Inactive</div>
            <div class="audio-controls">
                <div class="device-select">
                    <label for="voiceModel">Voice Model:</label>
                    <select id="voiceModel"></select>
                </div>
            </div>
            <div class="controls">
                <label class="toggle">
                    <input type="checkbox" id="showLogs">
                    <span class="slider"></span>
                </label>
                <label for="showLogs" class="toggle-label">Show Debug Logs</label>
            </div>
            <div class="controls">
                <button id="testButton" style="padding: 10px; margin: 5px; background: #28a745; color: white; border: none; border-radius: 5px;">
                    Test Button (3s)
                </button>
            </div>
            <hr>
            <div class="logs-container syncscroll" name="log-container" id="logsContainer" style="display: none;">
                <div id="logs" class="logs"></div>
            </div>
        </div>
        <div class="content-container syncscroll" name="log-container">
            <div id="conversation" class="conversation-panel"></div>
        </div>
    </div>

    <!-- Press to Speak Button -->
    <div class="speak-button-container">
        <button id="speakButton" class="speak-button" disabled>
            <span class="speak-button-text">Hold to Speak</span>
        </button>
    </div>

    <script>
        document.addEventListener("DOMContentLoaded", () => {
            const startButton = document.getElementById('startButton');
            const statusDiv = document.getElementById('status');
            const logsDiv = document.getElementById('logs');
            const conversationDiv = document.getElementById('conversation');
            const voiceModelSelect = document.getElementById('voiceModel');
            const showLogsCheckbox = document.getElementById('showLogs');
            const logsContainer = document.getElementById('logsContainer');
            const speakButton = document.getElementById('speakButton');
            const testButton = document.getElementById('testButton');

            let socket = null;
            let audioContext = null;
            let audioWorkletNode = null;
            let microphoneStream = null;
            let isActive = false;
            let isMuted = true; // Start muted, only speak when button is pressed
            let isAgentSpeaking = false; // Track when agent is playing audio
            let isAgentProcessing = false; // Track when agent is processing user input
            let audioQueue = [];
            let nextPlayTime = 0; // For continuous audio scheduling
            let lastAudioSendTime = 0;
            const AUDIO_SEND_INTERVAL = 20; // Send audio every 20ms (was 100ms - too aggressive)

            // --- UI and Logging ---

            function setStatus(message) {
                statusDiv.textContent = `Status: ${message}`;
            }

            function logMessage(message, type = 'info') {
                const timestamp = new Date().toLocaleTimeString();
                const logClass = type === 'error' ? 'log-error' : type === 'warn' ? 'log-warn' : type === 'user' ? 'log-user' : 'log-info';
                logsDiv.innerHTML += `<div class="${logClass}">[${timestamp}] ${message}</div>`;
                logsDiv.scrollTop = logsDiv.scrollHeight;
            }

            function addConversationMessage(role, text) {
                const messageBubble = document.createElement('div');
                messageBubble.className = `message-bubble ${role}`;
                messageBubble.textContent = text;
                conversationDiv.appendChild(messageBubble);
                conversationDiv.scrollTop = conversationDiv.scrollHeight;
            }

            // --- Scroll Syncing ---
            const syncScrollContainers = document.querySelectorAll('.syncscroll');
            syncScrollContainers.forEach(el => {
                el.addEventListener('scroll', () => {
                    const scrollY = el.scrollTop;
                    syncScrollContainers.forEach(otherEl => {
                        if (otherEl !== el) {
                            otherEl.scrollTop = scrollY;
                        }
                    });
                });
            });

            // --- API Calls ---

            async function fetchVoiceModels() {
                try {
                    const response = await fetch('/tts-models');
                    const data = await response.json();
                    if (data.models) {
                        voiceModelSelect.innerHTML = '';
                        data.models.forEach(model => {
                            const option = document.createElement('option');
                            option.value = model.name;
                            option.textContent = model.display_name;
                            voiceModelSelect.appendChild(option);
                        });
                        voiceModelSelect.value = 'aura-2-thalia-en'; // Default
                    } else {
                        logMessage('Failed to load voice models.', 'error');
                    }
                } catch (error) {
                    logMessage(`Error fetching voice models: ${error}`, 'error');
                }
            }
            
            // --- Core Audio Logic ---

            async function startAudio() {
                if (isActive) return;
                setStatus('Initializing...');
                logMessage('Starting audio pipeline...');

                try {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                    if (audioContext.state === 'suspended') await audioContext.resume();

                    await audioContext.audioWorklet.addModule('/audio-processor.js');
                    audioWorkletNode = new AudioWorkletNode(audioContext, 'audio-processor');

                    microphoneStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: { sampleRate: 16000, channelCount: 1 }
                    });
                    const microphone = audioContext.createMediaStreamSource(microphoneStream);
                    microphone.connect(audioWorkletNode);

                    audioWorkletNode.port.onmessage = (event) => {
                        // Always log audio capture for debugging
                        if (Math.random() < 0.1) { // 10% of chunks for debugging
                            logMessage(`ðŸŽ™ï¸ Audio captured: ${event.data.byteLength} bytes, isMuted: ${isMuted}, isAgentSpeaking: ${isAgentSpeaking}, socketConnected: ${socket?.connected}`);
                        }
                        
                        if (socket && socket.connected && !isMuted && !isAgentSpeaking) {
                            try {
                                // Send audio only when speak button is pressed and agent is not speaking
                                socket.emit('user_audio', event.data);
                                
                                // Log audio data being sent more frequently for debugging
                                if (Math.random() < 0.05) { // 5% of chunks
                                    logMessage(`ðŸ“¤ SENDING user audio: ${event.data.byteLength} bytes`);
                                }
                            } catch (error) {
                                logMessage(`âŒ ERROR sending audio: ${error}`, 'error');
                                // Try to reconnect socket if audio sending fails
                                if (!socket.connected) {
                                    logMessage('ðŸ”„ Socket disconnected during audio send, reconnecting...');
                                    socket.connect();
                                }
                            }
                        } else {
                            // Log why audio is NOT being sent
                            if (Math.random() < 0.02) { // 2% of chunks
                                const reason = !socket ? 'No socket' : 
                                              !socket.connected ? 'Socket disconnected' :
                                              isMuted ? 'Muted' : 
                                              isAgentSpeaking ? 'Agent speaking' : 'Unknown';
                                logMessage(`âŒ NOT sending audio - Reason: ${reason}`);
                                
                                // If socket is disconnected but we're trying to speak, attempt reconnect
                                if (!socket?.connected && !isMuted) {
                                    logMessage('ðŸ”„ Attempting socket reconnect while speaking...');
                                    socket?.connect();
                                }
                            }
                        }
                    };

                    isActive = true;
                    startButton.textContent = 'Stop Voice Agent';
                    setStatus('Connected, starting agent...');
                    logMessage('Audio pipeline ready.');
                    logMessage(`Microphone connected - Sample rate: ${audioContext.sampleRate}Hz`);
                    logMessage(`Audio mode: Press to Speak button only`);
                    
                    // Initialize states for new session
                    isAgentSpeaking = false;
                    isAgentProcessing = false;
                    isMuted = true;
                    updateSpeakButtonState(); // This should keep button disabled until agent is ready
                    
                    connectSocket();

                } catch (error) {
                    logMessage(`Failed to start audio: ${error}`, 'error');
                    if (error.name === 'NotAllowedError') {
                        logMessage('Microphone permission denied. Please allow microphone access and try again.', 'error');
                    } else if (error.name === 'NotFoundError') {
                        logMessage('No microphone found. Please connect a microphone and try again.', 'error');
                    }
                    setStatus('Error');
                    isActive = false;
                }
            }

            function stopAudio() {
                if (!isActive) return;
                isActive = false;
                isAgentSpeaking = false;
                isAgentProcessing = false;
                isMuted = true;
                
                logMessage('Stopping audio pipeline...');
                if (socket) {
                    socket.emit('stop_voice_agent');
                    socket.disconnect();
                }
                if (microphoneStream) {
                    microphoneStream.getTracks().forEach(track => track.stop());
                }
                if (audioContext && audioContext.state !== 'closed') {
                    audioContext.close();
                }
                audioQueue = [];
                nextPlayTime = 0;
                
                setStatus('Inactive');
                startButton.textContent = 'Start Voice Agent';
                
                // Reset speak button to disabled state
                speakButton.disabled = true;
                speakButton.style.opacity = '0.6';
                speakButton.querySelector('.speak-button-text').textContent = 'Hold to Speak';
                speakButton.style.background = 'linear-gradient(135deg, #007bff, #0056b3)';
            }

            function playNextAudioChunk() {
                if (audioQueue.length === 0 || !audioContext) {
                    // Audio queue is empty, but we'll rely primarily on AgentAudioDone message
                    if (isAgentSpeaking) {
                        logMessage(`ðŸ”„ Audio queue empty, checking for remaining audio...`);
                        setTimeout(() => {
                            logMessage(`ðŸ” Checking conditions: audioQueue.length=${audioQueue.length}, isAgentSpeaking=${isAgentSpeaking}`);
                            if (audioQueue.length === 0) { // Double check after delay
                                isAgentSpeaking = false;
                                isAgentProcessing = false;
                                logMessage('ðŸ Audio playback finished - ready for user input');
                                setStatus('Agent Ready - Press button to speak');
                                updateSpeakButtonState();
                            }
                        }, 100); // Much shorter delay since AgentAudioDone should handle most cases
                    }
                    return;
                }

                const audioData = audioQueue.shift();
                
                if (audioContext.state === 'suspended') {
                    audioContext.resume().then(() => {
                        playRawPCM(audioData);
                    });
                } else {
                    playRawPCM(audioData);
                }
            }

            function playRawPCM(audioData) {
                try {
                    // Convert Uint8Array to Int16Array (16-bit PCM)
                    const numSamples = audioData.length / 2;
                    const pcmData = new Int16Array(audioData.buffer, audioData.byteOffset, numSamples);
                    
                    // Create AudioBuffer
                    const audioBuffer = audioContext.createBuffer(1, numSamples, 24000);
                    const channelData = audioBuffer.getChannelData(0);
                    
                    // Convert Int16 to Float32 and fill the buffer
                    for (let i = 0; i < numSamples; i++) {
                        const sample = pcmData[i];
                        channelData[i] = sample / 32768.0;
                    }
                    
                    // Schedule the buffer for continuous playback
                    const source = audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioContext.destination);
                    
                    // Calculate when to start this chunk for smooth playback
                    const currentTime = audioContext.currentTime;
                    if (nextPlayTime <= currentTime) {
                        nextPlayTime = currentTime + 0.05; // Larger buffer (50ms) to prevent cutoff
                    }
                    
                    source.start(nextPlayTime);
                    nextPlayTime += audioBuffer.duration; // Schedule next chunk right after this one
                    
                    // Log less frequently
                    if (Math.random() < 0.02) { // 2% of chunks
                        logMessage(`Playing audio chunk: ${numSamples} samples, scheduled at ${nextPlayTime.toFixed(3)}s`);
                    }
                    
                } catch (error) {
                    logMessage(`Error playing raw PCM: ${error}`, 'error');
                    console.error('Raw PCM playback error:', error);
                }
            }

            // --- WebSocket Logic ---

            function connectSocket() {
                if (socket && socket.connected) {
                    logMessage('ðŸ“¡ Socket already connected');
                    return;
                }

                logMessage('ðŸ“¡ Connecting to socket...');
                socket = io({
                    transports: ['websocket', 'polling'], // Try WebSocket first, fallback to polling
                    upgrade: true,
                    rememberUpgrade: true,
                    timeout: 20000,
                    forceNew: true
                });

                socket.on('connect', () => {
                    logMessage('ðŸ“¡ Socket connected successfully.');
                    setStatus('Connected, starting agent...');
                    const sessionConfig = {
                        voiceModel: voiceModelSelect.value,
                    };
                    socket.emit('start_voice_agent', sessionConfig);
                });

                socket.on('disconnect', (reason) => {
                    logMessage(`ðŸ“¡ Socket disconnected: ${reason}`, 'warn');
                    setStatus('Disconnected - Reconnecting...');
                    
                    // Force reconnection after a short delay
                    setTimeout(() => {
                        if (!socket.connected) {
                            logMessage('ðŸ“¡ Attempting to reconnect...');
                            socket.connect();
                        }
                    }, 2000);
                });

                socket.on('connect_error', (error) => {
                    logMessage(`ðŸ“¡ Socket connection error: ${error}`, 'error');
                    setStatus('Connection Error');
                });

                socket.on('reconnect', (attemptNumber) => {
                    logMessage(`ðŸ“¡ Socket reconnected after ${attemptNumber} attempts`);
                    setStatus('Reconnected');
                    
                    // Restart voice agent if we were active
                    if (isActive) {
                        const sessionConfig = {
                            voiceModel: voiceModelSelect.value,
                        };
                        socket.emit('start_voice_agent', sessionConfig);
                    }
                });

                socket.on('agent_response', (data) => {
                    logMessage(`Agent Response: ${JSON.stringify(data)}`);
                    switch (data.type) {
                        case 'Welcome':
                            setStatus('Agent Ready');
                            logMessage('ðŸŽ‰ Agent connected - waiting for greeting audio');
                            // Don't enable button yet - wait for greeting audio to finish
                            break;
                        case 'ConversationText':
                            addConversationMessage('assistant', data.content);
                            // Agent is responding, so it's no longer processing user input
                            isAgentProcessing = false;
                            logMessage('ðŸ“ Agent response received - waiting for AgentAudioDone');
                            break;
                        case 'AgentAudioDone':
                            // Agent has finished speaking/responding - enable button immediately
                            isAgentSpeaking = false;
                            isAgentProcessing = false;
                            logMessage('âœ… AgentAudioDone received - enabling button immediately');
                            setStatus('Agent Ready - Press button to speak');
                            updateSpeakButtonState();
                            break;
                        case 'Error':
                            logMessage(`Agent Error: ${data.description}`, 'error');
                            setStatus('Error');
                            isAgentProcessing = false;
                            isAgentSpeaking = false; // Make sure we're not stuck in speaking state
                            updateSpeakButtonState();
                            break;
                    }
                });

                socket.on('agent_audio', (chunk) => {
                    audioQueue.push(new Uint8Array(chunk));
                    // Start agent speaking if not already
                    if (!isAgentSpeaking) {
                        isAgentSpeaking = true;
                        isAgentProcessing = false; // Clear processing state when agent starts speaking
                        logMessage('ðŸ—£ï¸ Agent started speaking');
                        setStatus('Agent speaking...');
                        updateSpeakButtonState(); // Disable button while agent speaks
                    }
                    playNextAudioChunk();
                });
            }

            // Function to update speak button state based on current conditions
            function updateSpeakButtonState() {
                const shouldEnable = isActive && !isAgentSpeaking && !isAgentProcessing;
                speakButton.disabled = !shouldEnable;
                speakButton.style.opacity = shouldEnable ? '1' : '0.6';
                
                logMessage(`Button state check - Active: ${isActive}, Speaking: ${isAgentSpeaking}, Processing: ${isAgentProcessing}, ShouldEnable: ${shouldEnable}`);
                
                if (shouldEnable) {
                    logMessage('âœ… Hold to Speak button ENABLED');
                    speakButton.style.background = 'linear-gradient(135deg, #007bff, #0056b3)';
                    speakButton.querySelector('.speak-button-text').textContent = 'Hold to Speak';
                } else {
                    logMessage(`âŒ Hold to Speak button DISABLED - Active: ${isActive}, Speaking: ${isAgentSpeaking}, Processing: ${isAgentProcessing}`);
                }
            }

            // Manual test function for debugging
            window.testButton = function() {
                logMessage('ðŸ§ª MANUAL TEST: Forcing button enable');
                isActive = true;
                isAgentSpeaking = false;
                isAgentProcessing = false;
                updateSpeakButtonState();
                logMessage(`ðŸ§ª TEST RESULT: Button disabled = ${speakButton.disabled}`);
            };
            
            // Additional debug functions
            window.checkStates = function() {
                logMessage(`ðŸ“Š CURRENT STATES: isActive=${isActive}, isAgentSpeaking=${isAgentSpeaking}, isAgentProcessing=${isAgentProcessing}, isMuted=${isMuted}`);
                logMessage(`ðŸ“Š BUTTON STATE: disabled=${speakButton.disabled}, opacity=${speakButton.style.opacity}`);
                logMessage(`ðŸ“Š AUDIO QUEUE: length=${audioQueue.length}`);
                logMessage(`ðŸ“Š SOCKET: connected=${socket?.connected}`);
            };
            
            window.forceEnable = function() {
                logMessage('ðŸ”§ FORCE ENABLE: Manually enabling button');
                speakButton.disabled = false;
                speakButton.style.opacity = '1';
                speakButton.style.background = 'linear-gradient(135deg, #007bff, #0056b3)';
                speakButton.querySelector('.speak-button-text').textContent = 'Hold to Speak';
                logMessage('ðŸ”§ Button force enabled');
            };
            
            window.testAudioSending = function() {
                logMessage('ðŸ§ª TESTING: Forcing audio unmute for 5 seconds');
                isMuted = false;
                setTimeout(() => {
                    isMuted = true;
                    logMessage('ðŸ§ª TESTING: Audio mute restored');
                }, 5000);
            };
            
            window.testButtonPress = function() {
                logMessage('ðŸ§ª MOBILE TEST: Simulating button press for 3 seconds');
                startSpeaking();
                setTimeout(() => {
                    stopSpeaking();
                }, 3000);
            };
            
            window.forceSocketConnect = function() {
                logMessage('ðŸ”Œ FORCE SOCKET: Manually connecting socket');
                if (!socket) {
                    connectSocket();
                } else {
                    socket.connect();
                }
            };
            
            window.checkAudio = function() {
                logMessage(`ðŸŽ™ï¸ AUDIO STATUS:`);
                logMessage(`  - audioContext: ${audioContext ? 'EXISTS' : 'NULL'}`);
                logMessage(`  - audioContext.state: ${audioContext?.state}`);
                logMessage(`  - audioWorkletNode: ${audioWorkletNode ? 'EXISTS' : 'NULL'}`);
                logMessage(`  - microphoneStream: ${microphoneStream ? 'EXISTS' : 'NULL'}`);
                logMessage(`  - microphoneStream.active: ${microphoneStream?.active}`);
                if (microphoneStream) {
                    logMessage(`  - microphone tracks: ${microphoneStream.getTracks().length}`);
                    microphoneStream.getTracks().forEach((track, i) => {
                        logMessage(`    Track ${i}: ${track.kind}, enabled: ${track.enabled}, readyState: ${track.readyState}`);
                    });
                }
            };
            
            window.checkSocket = function() {
                logMessage(`ðŸ“¡ SOCKET STATUS:`);
                logMessage(`  - socket exists: ${socket ? 'YES' : 'NO'}`);
                logMessage(`  - socket.connected: ${socket?.connected}`);
                logMessage(`  - socket.id: ${socket?.id}`);
                logMessage(`  - socket.readyState: ${socket?.readyState}`);
            };
            
            window.reconnectSocket = function() {
                logMessage('ðŸ”„ MANUAL RECONNECT: Forcing socket reconnection');
                if (socket) {
                    socket.disconnect();
                }
                setTimeout(() => {
                    connectSocket();
                }, 1000);
            };
            
            window.restartAgent = function() {
                logMessage('ðŸ”„ RESTARTING AGENT: Full restart');
                // Reset all states
                isAgentSpeaking = false;
                isAgentProcessing = false;
                isMuted = true;
                
                // Reconnect socket
                if (socket) {
                    socket.disconnect();
                }
                setTimeout(() => {
                    connectSocket();
                }, 1000);
                
                // Update button state
                updateSpeakButtonState();
                logMessage('ðŸ”„ Agent restart initiated');
            };
            
            // Periodic socket health check
            setInterval(() => {
                if (socket && !socket.connected && isActive) {
                    logMessage('âš ï¸ HEALTH CHECK: Socket disconnected while active, attempting reconnect');
                    socket.connect();
                }
            }, 5000); // Check every 5 seconds

            // Press-and-hold functionality for speak button
            function startSpeaking() {
                logMessage(`ðŸŽ¤ startSpeaking() called - Button disabled: ${speakButton.disabled}, isAgentSpeaking: ${isAgentSpeaking}, isAgentProcessing: ${isAgentProcessing}, isActive: ${isActive}`);
                logMessage(`ðŸŽ¤ Current muted state BEFORE: ${isMuted}`);
                
                if (!isAgentSpeaking && !isAgentProcessing && isActive) {
                    isMuted = false;
                    logMessage('âœ… UNMUTED - Now capturing audio', 'user');
                    logMessage(`ðŸŽ¤ Current muted state AFTER: ${isMuted}`);
                    setStatus('Listening...');
                    speakButton.querySelector('.speak-button-text').textContent = 'Speaking...';
                    speakButton.style.background = 'linear-gradient(135deg, #28a745, #1e7e34)';
                } else {
                    logMessage(`âŒ Cannot start speaking - conditions not met`);
                }
            }

            function stopSpeaking() {
                logMessage(`ðŸ›‘ stopSpeaking() called - isMuted BEFORE: ${isMuted}`);
                if (!isMuted) { // Only if we were actually speaking
                    isMuted = true;
                    logMessage(`ðŸ›‘ MUTED - Stopped capturing audio. isMuted AFTER: ${isMuted}`);
                    isAgentProcessing = true; // Agent is now processing
                    logMessage('Stopped speaking - Agent processing...');
                    setStatus('Agent processing...');
                    speakButton.querySelector('.speak-button-text').textContent = 'Processing...';
                    speakButton.style.background = 'linear-gradient(135deg, #ffc107, #e0a800)';
                    updateSpeakButtonState(); // Disable button while processing
                    
                    // Safety backup - if no AgentAudioDone received within 30 seconds, force enable
                    setTimeout(() => {
                        if (isAgentProcessing) {
                            logMessage('âš ï¸ SAFETY BACKUP: No AgentAudioDone received, forcing button enable');
                            isAgentProcessing = false;
                            isAgentSpeaking = false;
                            setStatus('Agent Ready - Press button to speak');
                            updateSpeakButtonState();
                        }
                    }, 30000); // 30 second backup
                } else {
                    logMessage(`ðŸ›‘ stopSpeaking() called but we weren't speaking (isMuted was already true)`);
                }
            }

            // Mouse events  
            speakButton.addEventListener('mousedown', (e) => {
                e.preventDefault();
                logMessage(`ðŸ–±ï¸ Mouse down event triggered`);
                startSpeaking();
            });

            speakButton.addEventListener('mouseup', () => {
                logMessage(`ðŸ–±ï¸ Mouse up event triggered`);
                stopSpeaking();
            });

            speakButton.addEventListener('mouseleave', () => {
                logMessage(`ðŸ–±ï¸ Mouse leave event triggered`);
                stopSpeaking();
            });

            // Touch events for mobile (FIXED)
            speakButton.addEventListener('touchstart', (e) => {
                e.preventDefault();
                e.stopPropagation();
                logMessage(`ðŸ“± Touch start event triggered`);
                startSpeaking();
            }, { passive: false });

            speakButton.addEventListener('touchend', (e) => {
                e.preventDefault();
                e.stopPropagation();
                logMessage(`ðŸ“± Touch end event triggered`);
                stopSpeaking();
            }, { passive: false });

            speakButton.addEventListener('touchcancel', (e) => {
                e.preventDefault();
                e.stopPropagation();
                logMessage(`ðŸ“± Touch cancel event triggered`);
                stopSpeaking();
            }, { passive: false });

            // Additional click event for debugging
            speakButton.addEventListener('click', (e) => {
                e.preventDefault();
                logMessage(`ðŸ‘† Click event triggered (this should NOT be used for speaking)`);
            });

            // Initialize speak button state
            speakButton.disabled = true;
            speakButton.style.opacity = '0.6';
            logMessage('Hold to Speak button initialized (disabled)');
            
            // Debug button element
            logMessage(`ðŸ” Button element found: ${speakButton ? 'YES' : 'NO'}`);
            logMessage(`ðŸ” Button ID: ${speakButton?.id}`);
            logMessage(`ðŸ” Button disabled: ${speakButton?.disabled}`);
            
            // Add error handling
            window.addEventListener('error', (e) => {
                logMessage(`âŒ JavaScript Error: ${e.message} at ${e.filename}:${e.lineno}`, 'error');
            });

            // --- Other Event Listeners ---

            startButton.addEventListener('click', () => {
                if (isActive) {
                    stopAudio();
                } else {
                    startAudio();
                    startButton.textContent = 'Stop Voice Agent';
                }
            });

            showLogsCheckbox.addEventListener('change', (e) => {
                if (e.target.checked) {
                    logsContainer.style.display = 'block';
                    logMessage('Debug logs are now visible');
                } else {
                    logsContainer.style.display = 'none';
                }
            });

            testButton.addEventListener('click', () => {
                logMessage('ðŸ§ª TEST BUTTON: Manual 3-second test started');
                testButtonPress();
            });

            fetchVoiceModels();
        });
    </script>
</body>
</html>